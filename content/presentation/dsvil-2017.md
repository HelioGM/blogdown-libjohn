+++
# Date this page was created.
date = "2017-04-26"

# Project title.
title = "DSVIL 2017 - Web Scraping"

# Project summary to display on homepage.
summary = "A Data Science & Visualization Institute invited a presentation on web scraping and creating your own data sources"

# Optional image to display on homepage (relative to `static/img/` folder).
image_preview = "scraping_propolis.jpg"

# Tags: can be used for filtering projects.
# Example: `tags = ["api", "twitter","presentation"]`
tags = ["scraping","api","parsing","json"]

# Optional external URL for project (replaces project detail page).
# external_link = ""

# Does the project detail page use math formatting?
math = false

# Optional featured image (relative to `static/img/` folder).
[header]
image = "scraping_propolis-short.jpg"
caption = "[Web] Scraping [Propolis]"

+++

&nbsp;

Preexisting and clean data sets such as the General Social Survey (GSS) 
or Census data are readily available, cover long periods of time, 
and have well documented codebooks. Meanwhile, researchers increasingly want 
to gather their own data from websites which provides a different 
layer of complexity; accessing content from these sources requires different 
tools and new techniques.  In this workshop we will use an open-source data 
wrangling tool (OpenRefine) to gather and clean data from webpages, 
and "crawl" whole websites, discuss and use Application 
Programming Interfaces (API), and give examples of how 
APIs are used with social media sources such as Twitter.


#### Additional Resources

- [Slides](https://libjohn.github.io/dsvil2017/slides.html) 

#### Date
2017-04-26

