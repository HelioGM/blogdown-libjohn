+++
# Date this page was created.
date = "2017-04-26"

# Project title.
title = "DSVIL 2017 - Web Scraping"

# Project summary to display on homepage.
summary = "The Data Science & Visualization Institute invited a presentation on web scraping and creating customized data sources"

# Optional image to display on homepage (relative to `static/img/` folder).
image_preview = "scraping_propolis.jpg"

# Tags: can be used for filtering projects.
# Example: `tags = ["api", "twitter","presentation"]`
tags = ["scraping","api","parsing","json"]

# Optional external URL for project (replaces project detail page).
# external_link = ""

# Does the project detail page use math formatting?
math = false

# Optional featured image (relative to `static/img/` folder).
[header]
image = "scraping_propolis-short.jpg"
caption = "[Web] Scraping [Propolis]"

+++

&nbsp;

Preexisting clean data sets such as the General Social Survey (GSS) or Census data, for example, are readily available, cover long periods of time, and have well documented codebooks. However, some people want to gather their own data. Recent tools and techniques for finding and compiling data from webpages, whole websites or social media sources have become more accessible.  Exploiting these web scraping techniques provides a different layer of complexity.

In this workshop we will use an open-source data wrangling tool (OpenRefine) to gather and clean data from webpages, and "crawl" whole websites, discuss and use Application Programming Interfaces (API), and give examples of how APIs are used with social media sources such as Twitter.


#### Additional Resources

- [Slides](/project/custom/dsvil2017/slides.html) 

#### Date
2017-04-26

